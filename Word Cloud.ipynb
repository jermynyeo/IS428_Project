{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: pillow in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: contractions in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (0.1.66)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "Requirement already satisfied: pyahocorasick in /Users/mr/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "import wordcloud\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import glob \n",
    "\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "STEMMER = PorterStemmer()\n",
    "PUNCTUATIONS = r'[\\!\\(\\)\\-\\[\\]\\{\\}\\;\\:\\\"\\\\\\,\\<\\>\\.\\/\\?\\@\\#\\$\\%\\^\\&\\*\\_\\~]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getCSVData(file):\n",
    "    df = pd.read_csv(file)\n",
    "    show = file.split(\"/\")[-1][:-4]\n",
    "    data = df.loc[:, [\"text\"]]\n",
    "    data[\"text_clean\"] = data.text.apply(lambda x: cleanText(x, show))\n",
    "    data[\"hashtags\"] = data.text.apply(lambda x: getHashtags(x, show.replace(\" \", \"\")))\n",
    "    return data\n",
    "\n",
    "\n",
    "def getJSONData(file):\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    show = file.split(\"/\")[-1][:-5]\n",
    "    data = df[df.lang == \"en\"].loc[:, ['content']]\n",
    "    data[\"text_clean\"] = data.content.apply(lambda x: cleanText(x, show))\n",
    "    data[\"hashtags\"] = data.content.apply(lambda x: getHashtags(x, show.replace(\" \", \"\")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(tweet, show_name): \n",
    "    STOPWORDS_THIS = STOPWORDS + []\n",
    "    STOPWORDS_THIS.extend([\"netflix\",\"episode\", show_name] + show_name.split())\n",
    "    tweet_text = tweet.split()\n",
    "\n",
    "    # remove hashtags\n",
    "    tweet_no_hash = [t.lower() for t in tweet_text if not re.match(r\"#.\\w+\", t)]\n",
    "    \n",
    "    # remove punctuation\n",
    "    tweet_replace_sym = [re.sub(PUNCTUATIONS, \"\",t) for t in tweet_no_hash]\n",
    "\n",
    "    #get words only and fix contarctions\n",
    "    tweet_words = [contractions.fix(t.lower()) for t in tweet_replace_sym if re.match(r\"(\\w+)\", t)]\n",
    "    \n",
    "    words = ' '.join(tweet_words)\n",
    "    tweet_words =  words.split()\n",
    "\n",
    "    #remove stop words, stem words\n",
    "\n",
    "    tweet_no_stop = [STEMMER.stem(t) for t in tweet_words if t not in STOPWORDS_THIS]\n",
    "\n",
    "\n",
    "    #remove links\n",
    "    tweet_remove_link = [t for t in tweet_no_stop if not re.match(r\"^http\", t)]\n",
    "    \n",
    "    #remove from stop words \n",
    "    \n",
    "    return ' '.join(tweet_remove_link)\n",
    "    \n",
    "def getHashtags(tweet, show_name): \n",
    "    tweet_text = tweet.split()\n",
    "    hashtags = [t.lower() for t in tweet_text if re.match(r\"#.\\w+\", t)]\n",
    "    remove_stop_hash = [hashtag for hashtag in hashtags if show_name not in hashtag and \"netflix\" not in hashtag and hashtag[1:].encode().isalpha()]\n",
    "    tweet_replace_sym = [re.sub(PUNCTUATIONS, \"\",t) for t in remove_stop_hash]\n",
    "    return ' '.join(tweet_replace_sym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genWC(df, show, wc_type, mask_type):\n",
    "    WC_DIR = \"./project/static/wc\"\n",
    "    MASK_DIR = \"./project/static/mask\"\n",
    "\n",
    "    from PIL import Image\n",
    "    stopwords = set(STOPWORDS)\n",
    "\n",
    "    mask = np.array(Image.open(f\"{MASK_DIR}/{show}_mask.{mask_type}\"))\n",
    "\n",
    "    image_colors = ImageColorGenerator(mask)\n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, stopwords=STOPWORDS, background_color=\"white\", max_words=1000, mask=mask).generate(' '.join(df))\n",
    "\n",
    "    # create word cloud image\n",
    "    plt.figure()\n",
    "    plt.figure(figsize=(39.714, 18.759), dpi=300)\n",
    "    plt.axis(\"off\")\n",
    "    im2 = plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "    im1 = plt.imshow(mask, alpha = 0.075)\n",
    "\n",
    "    # store to file\n",
    "    plt.savefig(f\"{WC_DIR}/{show}_{wc_type}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# genWC(data.text_clean, \"squidgame_text\")\n",
    "# genWC(data.hashtags, \"squidgame_hashtags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"Data/tweets/\"\n",
    "mask_file_types = {\"13 reasons why\": \"png\", \"all of us are dead\": \"png\", \"bridgerton\": \"png\", \"maid\": \"png\", \"money heist\":\"png\", \"red notice\": \"jpg\", \"squid game\": \"png\", \"stranger things\":\"jpg\", \"the witcher\":\"jpg\", \"you\": \"png\" }\n",
    "csv_files = glob.glob(f\"Data/tweets/*.csv\")\n",
    "for file in csv_files: \n",
    "    data = getCSVData(file)\n",
    "    show = file.split(\"/\")[-1][:-4]\n",
    "    genWC(data.text_clean, show, \"text\", mask_file_types[show])\n",
    "    genWC(data.hashtags, show, \"hashtags\", mask_file_types[show])  \n",
    "\n",
    "json_files = glob.glob(f\"Data/tweets/*.json\")\n",
    "for file in json_files:\n",
    "    data = getJSONData(file)\n",
    "    show = file.split(\"/\")[-1][:-5]\n",
    "    genWC(data.text_clean, show, \"text\", mask_file_types[show])\n",
    "    genWC(data.hashtags, show, \"hashtags\", mask_file_types[show])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd3e321934a89039be24996b5fc6782ee7b909f22b294d7652f2f30f3effe4cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
